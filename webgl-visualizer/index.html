<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <style>
      body {
        margin: 0;
        overflow: hidden;
        background: #000;
        color: #fff;
        font-family: sans-serif;
      }
      canvas {
        display: block;
      }
      #controls {
        position: fixed;
        top: 10px;
        left: 10px;
        background: rgba(0, 0, 0, 0.6);
        padding: 10px;
        border-radius: 5px;
        z-index: 100;
      }
      #modeDisplay {
        margin-bottom: 10px;
        font-weight: bold;
      }
      button,
      input {
        margin: 5px;
      }
    </style>
  </head>
  <body>
    <canvas id="canvas"></canvas>
    <div id="controls">
      <div id="modeDisplay">Mode: Loading...</div>
      <input type="file" id="audioUpload" accept="audio/*" />
      <button id="startRecording">Start Recording</button>
      <button id="stopRecording" disabled>Stop Recording</button>
      <br />
      <label for="userColor">User Color:</label>
      <input type="color" id="userColor" value="#ff0077" />
      <div style="margin-top: 10px;">Use ← and → keys to switch animations</div>
      <label for="canvasWidth">Canvas Width:</label>
      <input type="number" id="canvasWidth" value="800" min="100" max="4000" />
      <label for="canvasHeight">Canvas Height:</label>
      <input type="number" id="canvasHeight" value="600" min="100" max="4000" />
    </div>
    <script>
      const canvas = document.getElementById("canvas");
      const gl = canvas.getContext("webgl", {
        antialias: true,
        preserveDrawingBuffer: true,
      });
      if (!gl) {
        alert("WebGL not supported");
        throw new Error("WebGL not supported");
      }
      function resizeCanvas() {
        const widthInput = document.getElementById("canvasWidth").value;
        const heightInput = document.getElementById("canvasHeight").value;
        const userWidth = parseInt(widthInput, 10) || window.innerWidth;
        const userHeight = parseInt(heightInput, 10) || window.innerHeight;
        const dpr = window.devicePixelRatio || 1;
        canvas.width = userWidth * dpr;
        canvas.height = userHeight * dpr;
        canvas.style.width = userWidth + "px";
        canvas.style.height = userHeight + "px";
        gl.viewport(0, 0, canvas.width, canvas.height);
      }
      document.getElementById("canvasWidth").addEventListener("input", resizeCanvas);
      document.getElementById("canvasHeight").addEventListener("input", resizeCanvas);
      window.addEventListener("resize", resizeCanvas);
      resizeCanvas();
      const vsSource = `
        attribute vec2 aPosition;
        void main(){
          gl_Position = vec4(aPosition, 0.0, 1.0);
        }
      `;
      const fsSourceWaves = `
        precision mediump float;
        uniform float uTime;
        uniform vec2 uResolution;
        uniform float uAudioLevel;
        uniform vec3 uUserColor;
        void main(void) {
          vec2 uv = (gl_FragCoord.xy - 0.5 * uResolution) / uResolution.y;
          float angle = atan(uv.y, uv.x);
          float radius = length(uv);
          float wave = sin(10.0 * radius - uTime * 2.0 + uAudioLevel * 5.0) + sin(5.0 * angle + uTime);
          vec3 base = vec3(0.5, 0.5, 0.5);
          vec3 col = mix(base, uUserColor, 0.5 + 0.5 * sin(uTime + wave));
          gl_FragColor = vec4(col, 1.0);
        }
      `;
      const fsSourceTunnel = `
        precision mediump float;
        uniform float uTime;
        uniform vec2 uResolution;
        uniform float uAudioLevel;
        uniform vec3 uUserColor;
        void main(void) {
          vec2 uv = (gl_FragCoord.xy - 0.5 * uResolution) / uResolution.y;
          float angle = atan(uv.y, uv.x);
          float radius = length(uv);
          float stripes = sin(10.0 * radius - uTime * 5.0 + uAudioLevel * 10.0);
          vec3 base = vec3(0.3, 0.3, 0.3);
          vec3 col = mix(base, uUserColor, 0.5 + 0.5 * cos(uTime + stripes + angle));
          gl_FragColor = vec4(col, 1.0);
        }
      `;
      const fsSourceSpectrum = `
        precision mediump float;
        uniform float uTime;
        uniform vec2 uResolution;
        uniform float uAudioLevel;
        uniform vec3 uUserColor;
        void main(void) {
          vec2 uv = gl_FragCoord.xy / uResolution.xy;
          float barWidth = 0.05;
          float index = floor(uv.x / barWidth);
          float modTime = mod(uTime + index, 1.0);
          float bar = step(0.5, fract(uv.y * 10.0 + modTime + uAudioLevel * 5.0));
          vec3 col = mix(vec3(0.0), uUserColor, bar);
          gl_FragColor = vec4(col, 1.0);
        }
      `;
      function compileShader(source, type) {
        const shader = gl.createShader(type);
        gl.shaderSource(shader, source);
        gl.compileShader(shader);
        if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
          const error = gl.getShaderInfoLog(shader);
          gl.deleteShader(shader);
          throw new Error("Shader compile error: " + error);
        }
        return shader;
      }
      function createProgram(fsSource) {
        const vertexShader = compileShader(vsSource, gl.VERTEX_SHADER);
        const fragmentShader = compileShader(fsSource, gl.FRAGMENT_SHADER);
        const program = gl.createProgram();
        gl.attachShader(program, vertexShader);
        gl.attachShader(program, fragmentShader);
        gl.linkProgram(program);
        if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
          const error = gl.getProgramInfoLog(program);
          gl.deleteProgram(program);
          throw new Error("Program link error: " + error);
        }
        return program;
      }
      const animations = [];
      const fsSources = [fsSourceWaves, fsSourceTunnel, fsSourceSpectrum];
      const modeNames = ["Waves", "Tunnel", "Spectrum"];
      for (let i = 0; i < fsSources.length; i++) {
        const program = createProgram(fsSources[i]);
        gl.useProgram(program);
        const uTime = gl.getUniformLocation(program, "uTime");
        const uResolution = gl.getUniformLocation(program, "uResolution");
        const uAudioLevel = gl.getUniformLocation(program, "uAudioLevel");
        const uUserColor = gl.getUniformLocation(program, "uUserColor");
        animations.push({
          name: modeNames[i],
          program,
          uniforms: { uTime, uResolution, uAudioLevel, uUserColor },
        });
      }
      let currentAnimationIndex = 0;
      const modeDisplay = document.getElementById("modeDisplay");
      function updateModeDisplay() {
        modeDisplay.textContent = "Mode: " + animations[currentAnimationIndex].name;
      }
      updateModeDisplay();
      const vertices = new Float32Array([
        -1, -1,   1, -1,   -1, 1,
        -1,  1,   1, -1,    1, 1
      ]);
      const buffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
      gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW);
      function bindAttributes(program) {
        const aPosition = gl.getAttribLocation(program, "aPosition");
        gl.enableVertexAttribArray(aPosition);
        gl.vertexAttribPointer(aPosition, 2, gl.FLOAT, false, 0, 0);
      }
      window.addEventListener("keydown", (e) => {
        if (e.key === "ArrowRight") {
          currentAnimationIndex = (currentAnimationIndex + 1) % animations.length;
          updateModeDisplay();
        } else if (e.key === "ArrowLeft") {
          currentAnimationIndex = (currentAnimationIndex - 1 + animations.length) % animations.length;
          updateModeDisplay();
        }
      });
      function hexToRgb(hex) {
        let r = parseInt(hex.slice(1, 3), 16) / 255;
        let g = parseInt(hex.slice(3, 5), 16) / 255;
        let b = parseInt(hex.slice(5, 7), 16) / 255;
        return [r, g, b];
      }
      let audioBuffer = null;
      let analyser = null;
      let dataArray = null;
      let sourceNode = null;
      const AudioContext = window.AudioContext || window.webkitAudioContext;
      const audioCtx = new AudioContext();
      const dest = audioCtx.createMediaStreamDestination();
      document.getElementById("audioUpload").addEventListener("change", async (e) => {
        const file = e.target.files[0];
        if (file) {
          const arrayBuffer = await file.arrayBuffer();
          audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
          console.log("Audio file loaded.");
        }
      });
      let startTime = null;
      function render(timestamp) {
        if (!startTime) startTime = timestamp;
        const elapsed = (timestamp - startTime) / 1000.0;
        const anim = animations[currentAnimationIndex];
        gl.useProgram(anim.program);
        bindAttributes(anim.program);
        gl.clearColor(0.0, 0.0, 0.0, 1.0);
        gl.clear(gl.COLOR_BUFFER_BIT);
        gl.uniform1f(anim.uniforms.uTime, elapsed);
        gl.uniform2f(anim.uniforms.uResolution, canvas.width, canvas.height);
        let audioLevel = 0.0;
        if (analyser && dataArray) {
          analyser.getByteFrequencyData(dataArray);
          let sum = 0;
          for (let i = 0; i < dataArray.length; i++) {
            sum += dataArray[i];
          }
          audioLevel = sum / dataArray.length / 255;
        }
        gl.uniform1f(anim.uniforms.uAudioLevel, audioLevel);
        const userColorHex = document.getElementById("userColor").value;
        const [r, g, b] = hexToRgb(userColorHex);
        if (anim.uniforms.uUserColor)
          gl.uniform3f(anim.uniforms.uUserColor, r, g, b);
        
        gl.drawArrays(gl.TRIANGLES, 0, 6);
        requestAnimationFrame(render);
      }
      requestAnimationFrame(render);
      let mediaRecorder;
      let chunks = [];
      const videoBitrate = 10000000;
      document.getElementById("startRecording").addEventListener("click", async () => {
        await audioCtx.resume();
        chunks = [];
        if (audioBuffer) {
          if (sourceNode) {
            try { sourceNode.stop(); } catch (e) {}
          }
          sourceNode = audioCtx.createBufferSource();
          sourceNode.buffer = audioBuffer;
          const gainNode = audioCtx.createGain();
          sourceNode.connect(gainNode);
          analyser = audioCtx.createAnalyser();
          analyser.fftSize = 512;
          dataArray = new Uint8Array(analyser.frequencyBinCount);
          gainNode.connect(analyser);
          gainNode.connect(audioCtx.destination);
          gainNode.connect(dest);
          sourceNode.start(0);
        }
        const canvasStream = canvas.captureStream(60);
        const audioStream = dest.stream;
        const tracks = [
          ...canvasStream.getTracks(),
          ...audioStream.getTracks()
        ];
        const combinedStream = new MediaStream(tracks);
        mediaRecorder = new MediaRecorder(combinedStream, {
          mimeType: "video/webm;codecs=vp9,opus",
          videoBitsPerSecond: videoBitrate,
        });
        mediaRecorder.ondataavailable = (e) => {
          if (e.data && e.data.size > 0) chunks.push(e.data);
        };
        mediaRecorder.onstop = () => {
          const blob = new Blob(chunks, { type: "video/webm" });
          const url = URL.createObjectURL(blob);
          const a = document.createElement("a");
          a.href = url;
          a.download = "visualization.webm";
          document.body.appendChild(a);
          a.click();
          URL.revokeObjectURL(url);
          a.remove();
        };
        mediaRecorder.start(1000);
        document.getElementById("startRecording").disabled = true;
        document.getElementById("stopRecording").disabled = false;
      });
      
      document.getElementById("stopRecording").addEventListener("click", () => {
        mediaRecorder.stop();
        document.getElementById("startRecording").disabled = false;
        document.getElementById("stopRecording").disabled = true;
        if (sourceNode) {
          try { sourceNode.stop(); } catch (e) {}
        }
      });
    </script>
  </body>
</html>