<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <style>
    body {
      margin: 0;
      overflow: hidden;
      background: #000;
      color: #fff;
      font-family: sans-serif;
    }
    canvas {
      display: block;
    }
    #controls {
      position: fixed;
      top: 10px;
      left: 10px;
      background: rgba(0, 0, 0, 0.8);
      padding: 15px;
      border-radius: 8px;
      z-index: 100;
      max-width: 300px;
    }
    #controls label,
    #controls input,
    #controls button,
    #controls select {
      display: block;
      margin: 8px 0;
      width: 100%;
    }
    #modeDisplay {
      font-weight: bold;
      margin-bottom: 10px;
    }
    /* Preview Panel */
    #previewContainer {
      position: fixed;
      bottom: 10px;
      right: 10px;
      background: rgba(0, 0, 0, 0.8);
      padding: 10px;
      border-radius: 8px;
      z-index: 101;
      display: none;
      max-width: 400px;
    }
    #previewContainer video {
      width: 100%;
      display: block;
      margin-bottom: 10px;
    }
    @media (max-width: 600px) {
      #controls {
        max-width: 90%;
        left: 5%;
      }
      #previewContainer {
        max-width: 90%;
        right: 5%;
      }
    }
  </style>
</head>
<body>
  <canvas id="visualizerCanvas"></canvas>
  <div id="controls">
    <div id="modeDisplay">Mode: Loading...</div>
    <label for="audioUpload">Load Audio File:</label>
    <input type="file" id="audioUpload" accept="audio/*" />
    <label for="qualitySelect">Recording Quality:</label>
    <select id="qualitySelect">
      <option value="low">Low (2.5 Mbps)</option>
      <option value="medium" selected>Medium (5 Mbps)</option>
      <option value="high">High (10 Mbps)</option>
    </select>
    <label for="canvasWidth">Canvas Width:</label>
    <input type="number" id="canvasWidth" value="800" min="100" max="4000" />
    <label for="canvasHeight">Canvas Height:</label>
    <input type="number" id="canvasHeight" value="600" min="100" max="4000" />
    <label for="userColor">User Color:</label>
    <input type="color" id="userColor" value="#ff0077" />
    <div style="margin:10px 0;">Use ←/→ keys to switch animations</div>
    <button id="startRecording">Start Recording</button>
    <button id="stopRecording" disabled>Stop Recording</button>
  </div>
  <div id="previewContainer">
    <video id="previewVideo" controls></video>
    <button id="downloadRecording">Download Recording</button>
    <button id="closePreview">Close Preview</button>
  </div>
  <script>
    const canvas = document.getElementById("visualizerCanvas");
    const gl = canvas.getContext("webgl", {
      antialias: true,
      preserveDrawingBuffer: true,
    });
    if (!gl) {
      alert("WebGL not supported");
      throw new Error("WebGL not supported");
    }
    const qualitySettings = {
      low: { videoBitsPerSecond: 2500000 },
      medium: { videoBitsPerSecond: 5000000 },
      high: { videoBitsPerSecond: 10000000 }
    };
    function resizeCanvas() {
      const widthInput = document.getElementById("canvasWidth").value;
      const heightInput = document.getElementById("canvasHeight").value;
      const userWidth = parseInt(widthInput, 10) || window.innerWidth;
      const userHeight = parseInt(heightInput, 10) || window.innerHeight;
      const dpr = window.devicePixelRatio || 1;
      canvas.width = userWidth * dpr;
      canvas.height = userHeight * dpr;
      canvas.style.width = userWidth + "px";
      canvas.style.height = userHeight + "px";
      gl.viewport(0, 0, canvas.width, canvas.height);
    }
    document.getElementById("canvasWidth").addEventListener("input", resizeCanvas);
    document.getElementById("canvasHeight").addEventListener("input", resizeCanvas);
    window.addEventListener("resize", resizeCanvas);
    resizeCanvas();
    class ShaderProgram {
      constructor(vertexSrc, fragmentSrc) {
        this.program = this.createProgram(vertexSrc, fragmentSrc);
      }
      createShader(source, type) {
        const shader = gl.createShader(type);
        gl.shaderSource(shader, source);
        gl.compileShader(shader);
        if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
          const error = gl.getShaderInfoLog(shader);
          gl.deleteShader(shader);
          throw new Error("Shader compile error: " + error);
        }
        return shader;
      }
      createProgram(vertexSrc, fragmentSrc) {
        const vertexShader = this.createShader(vertexSrc, gl.VERTEX_SHADER);
        const fragmentShader = this.createShader(fragmentSrc, gl.FRAGMENT_SHADER);
        const program = gl.createProgram();
        gl.attachShader(program, vertexShader);
        gl.attachShader(program, fragmentShader);
        gl.linkProgram(program);
        if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
          const error = gl.getProgramInfoLog(program);
          gl.deleteProgram(program);
          throw new Error("Program link error: " + error);
        }
        return program;
      }
      use() {
        gl.useProgram(this.program);
      }
      getAttribLocation(name) {
        return gl.getAttribLocation(this.program, name);
      }
      getUniformLocation(name) {
        return gl.getUniformLocation(this.program, name);
      }
    }
    class AnimationModule {
      constructor(name, fragmentSrc) {
        this.name = name;
        this.shader = new ShaderProgram(vsSource, fragmentSrc);
        this.uniforms = {
          uTime: gl.getUniformLocation(this.shader.program, "uTime"),
          uResolution: gl.getUniformLocation(this.shader.program, "uResolution"),
          uAudioLevel: gl.getUniformLocation(this.shader.program, "uAudioLevel"),
          uUserColor: gl.getUniformLocation(this.shader.program, "uUserColor"),
        };
      }
      use() {
        this.shader.use();
      }
    }
    const vsSource = `
      attribute vec2 aPosition;
      void main(){
        gl_Position = vec4(aPosition, 0.0, 1.0);
      }
    `;
    const fsSourceWaves = `
      precision mediump float;
      uniform float uTime;
      uniform vec2 uResolution;
      uniform float uAudioLevel;
      uniform vec3 uUserColor;
      void main(void) {
        vec2 uv = (gl_FragCoord.xy - 0.5 * uResolution) / uResolution.y;
        float angle = atan(uv.y, uv.x);
        float radius = length(uv);
        float wave = sin(10.0 * radius - uTime * 2.0 + uAudioLevel * 5.0) + sin(5.0 * angle + uTime);
        vec3 base = vec3(0.5);
        vec3 col = mix(base, uUserColor, 0.5 + 0.5 * sin(uTime + wave));
        gl_FragColor = vec4(col, 1.0);
      }
    `;
    const fsSourceTunnel = `
      precision mediump float;
      uniform float uTime;
      uniform vec2 uResolution;
      uniform float uAudioLevel;
      uniform vec3 uUserColor;
      void main(void) {
        vec2 uv = (gl_FragCoord.xy - 0.5 * uResolution) / uResolution.y;
        float angle = atan(uv.y, uv.x);
        float radius = length(uv);
        float stripes = sin(10.0 * radius - uTime * 5.0 + uAudioLevel * 10.0);
        vec3 base = vec3(0.3);
        vec3 col = mix(base, uUserColor, 0.5 + 0.5 * cos(uTime + stripes + angle));
        gl_FragColor = vec4(col, 1.0);
      }
    `;
    const fsSourceSpectrum = `
      precision mediump float;
      uniform float uTime;
      uniform vec2 uResolution;
      uniform float uAudioLevel;
      uniform vec3 uUserColor;
      void main(void) {
        vec2 uv = gl_FragCoord.xy / uResolution;
        float barWidth = 0.05;
        float index = floor(uv.x / barWidth);
        float modTime = mod(uTime + index, 1.0);
        float bar = step(0.5, fract(uv.y * 10.0 + modTime + uAudioLevel * 5.0));
        vec3 col = mix(vec3(0.0), uUserColor, bar);
        gl_FragColor = vec4(col, 1.0);
      }
    `;
    const animationModules = [
      new AnimationModule("Waves", fsSourceWaves),
      new AnimationModule("Tunnel", fsSourceTunnel),
      new AnimationModule("Spectrum", fsSourceSpectrum)
    ];
    let currentAnimationIndex = 0;
    function updateModeDisplay() {
      document.getElementById("modeDisplay").textContent = "Mode: " + animationModules[currentAnimationIndex].name;
    }
    updateModeDisplay();
    const vertices = new Float32Array([
      -1, -1,   1, -1,   -1, 1,
      -1, 1,   1, -1,    1, 1
    ]);
    const buffer = gl.createBuffer();
    gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
    gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW);
    function bindAttributes(program) {
      const aPosition = gl.getAttribLocation(program, "aPosition");
      gl.enableVertexAttribArray(aPosition);
      gl.vertexAttribPointer(aPosition, 2, gl.FLOAT, false, 0, 0);
    }
    let audioBuffer = null, analyser = null, dataArray = null, sourceNode = null;
    const AudioContext = window.AudioContext || window.webkitAudioContext;
    const audioCtx = new AudioContext();
    const dest = audioCtx.createMediaStreamDestination();
    document.getElementById("audioUpload").addEventListener("change", async (e) => {
      const file = e.target.files[0];
      if (file) {
        const arrayBuffer = await file.arrayBuffer();
        audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
        console.log("Audio file loaded.");
      }
    });
    let startTime = null;
    function render(timestamp) {
      if (!startTime) startTime = timestamp;
      const elapsed = (timestamp - startTime) / 1000.0;
      const animModule = animationModules[currentAnimationIndex];
      animModule.use();
      bindAttributes(animModule.shader.program);
      gl.clearColor(0.0, 0.0, 0.0, 1.0);
      gl.clear(gl.COLOR_BUFFER_BIT);
      gl.uniform1f(animModule.uniforms.uTime, elapsed);
      gl.uniform2f(animModule.uniforms.uResolution, canvas.width, canvas.height);
      let audioLevel = 0.0;
      if (analyser && dataArray) {
        analyser.getByteFrequencyData(dataArray);
        let sum = 0;
        for (let i = 0; i < dataArray.length; i++) {
          sum += dataArray[i];
        }
        audioLevel = sum / dataArray.length / 255;
      }
      gl.uniform1f(animModule.uniforms.uAudioLevel, audioLevel);
      const userColorHex = document.getElementById("userColor").value;
      const rgb = hexToRgb(userColorHex);
      gl.uniform3f(animModule.uniforms.uUserColor, rgb[0], rgb[1], rgb[2]);
      gl.drawArrays(gl.TRIANGLES, 0, 6);
      requestAnimationFrame(render);
    }
    requestAnimationFrame(render);
    function hexToRgb(hex) {
      let r = parseInt(hex.slice(1, 3), 16) / 255;
      let g = parseInt(hex.slice(3, 5), 16) / 255;
      let b = parseInt(hex.slice(5, 7), 16) / 255;
      return [r, g, b];
    }
    window.addEventListener("keydown", (e) => {
      if (e.key === "ArrowRight") {
        currentAnimationIndex = (currentAnimationIndex + 1) % animationModules.length;
        updateModeDisplay();
      } else if (e.key === "ArrowLeft") {
        currentAnimationIndex = (currentAnimationIndex - 1 + animationModules.length) % animationModules.length;
        updateModeDisplay();
      }
    });
    let mediaRecorder, chunks = [];
    const qualitySelect = document.getElementById("qualitySelect");
    const startBtn = document.getElementById("startRecording");
    const stopBtn = document.getElementById("stopRecording");
    const previewContainer = document.getElementById("previewContainer");
    const previewVideo = document.getElementById("previewVideo");
    const downloadBtn = document.getElementById("downloadRecording");
    const closePreviewBtn = document.getElementById("closePreview");
    startBtn.addEventListener("click", async () => {
      await audioCtx.resume();
      chunks = [];
      if (audioBuffer) {
        if (sourceNode) {
          try { sourceNode.stop(); } catch (e) {}
        }
        sourceNode = audioCtx.createBufferSource();
        sourceNode.buffer = audioBuffer;
        const gainNode = audioCtx.createGain();
        sourceNode.connect(gainNode);
        analyser = audioCtx.createAnalyser();
        analyser.fftSize = 512;
        dataArray = new Uint8Array(analyser.frequencyBinCount);
        gainNode.connect(analyser);
        gainNode.connect(audioCtx.destination);
        gainNode.connect(dest);
        sourceNode.start(0);
      }
      const canvasStream = canvas.captureStream(60);
      const audioStream = dest.stream;
      const tracks = [...canvasStream.getTracks(), ...audioStream.getTracks()];
      const combinedStream = new MediaStream(tracks);
      const selectedQuality = qualitySettings[qualitySelect.value];
      mediaRecorder = new MediaRecorder(combinedStream, {
        mimeType: "video/webm;codecs=vp9,opus",
        ...selectedQuality
      });
      mediaRecorder.ondataavailable = (e) => {
        if (e.data && e.data.size > 0) chunks.push(e.data);
      };
      mediaRecorder.onstop = () => {
        const blob = new Blob(chunks, { type: "video/webm" });
        const url = URL.createObjectURL(blob);
        previewVideo.src = url;
        previewVideo.load();
        previewContainer.style.display = "block";
        downloadBtn.onclick = () => {
          const a = document.createElement("a");
          a.href = url;
          a.download = "visualization.webm";
          document.body.appendChild(a);
          a.click();
          a.remove();
        };
      };
      mediaRecorder.start(1000);
      startBtn.disabled = true;
      stopBtn.disabled = false;
    });
    stopBtn.addEventListener("click", () => {
      mediaRecorder.stop();
      startBtn.disabled = false;
      stopBtn.disabled = true;
      if (sourceNode) {
        try { sourceNode.stop(); } catch (e) {}
      }
    });
    closePreviewBtn.addEventListener("click", () => {
      previewContainer.style.display = "none";
      previewVideo.src = "";
    });
  </script>
</body>
</html>